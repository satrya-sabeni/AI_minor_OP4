Stap 1 -> Images verzamelen. Ongeveer 100 van 1 gesture.
stap 2 -> Images labelen met behulp van VGG Image Annotator (online editor). Dit moet je doen met bounding boxes.
stap 3 -> De output van de labels moet je converten met behulp van de script ("tensorflow_api/create_school_tf_records.py") (dan heb je tf records)
stap 4 -> https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md ( ssd_mobilenet_v1_coco)
download coco; vervolgens ssd_mobilenet_v1_coco.config openen. Daarna edit het volgende
--
fine_tune_checkpoint: model.ckpt(verwijzing naar ckpt van ssd download)
num_steps: 8000
train_input_reader {
    label_map_path: (verwijzing naar label_map.pbtxt())
    tf_record_input_reader { . input_path: (verwijzing naar train.record)
}
eval_input_reader {
    label_map_path: (verwijzing naar label_map.pbtxt())
    tf_record_input_reader { . input_path: *(verwijzing naar eval.record)
}
--

verwijzing naar je eigen path ( waar je tf records staan)
stap 5 -> model_main.py runnen
--
python object_detection/model_main.py \
  --pipeline_config_path=./object_detection/school_dir/data_open_hand/ssd_mobilenet_v1.config \
  --model_dir=./object_detection/school_dir/model_dir \
  --num_train_steps=8000(aantal stappen) \
  --alsologtostderr
  --